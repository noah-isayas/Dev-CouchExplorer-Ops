Serverless, Function as a service
Serverløs arkitektur er en tilnærming innen programvareutvikling som gjør det mulig for utviklere å fokusere på å bygge og kjøre kildekoden uten å måtte ta for seg for den underliggende infrastrukturen. I dette miljøet håndteres rutinemessige vedlikeholdsoppgaver som installasjon av operativsystemer, oppdateringer, sikkerhetstiltak og overvåking av en skytjenesteleverandør (CSP). Selv om navnet kan antyde at dette utspiller seg i fravær av servere, betyr det egentlig at CSP tar for seg den underliggende serveradministrasjonen, noe som frigjør utviklere til å fokusere på koden og forretningslogikken.
En betydelig fordel ved serverløs arkitektur er at skyleverandører tilbyr ressurser basert på en "on-demand"-modell. Dette gjør at ressursene kan tildeles og skaleres dynamisk, både opp og ned, avhengig av behov. Resultatet er en mer fleksibel og kostnadseffektiv ressursstyring. Faktureringen starter når koden begynner å kjøre og avsluttes så fort prosessen er ferdig, noe som gir en høy grad av kostnadskontroll. Sammen med tjenester som IaaS (Infrastructure-as-a-Service) og FaaS (Function-as-a-Service) har serverløs arkitektur blitt et av de ledende tilbudene innen skytjenester. 
Container-teknologi
Mikrotjenestearkitektur er en tilnærming innen programvareutvikling der applikasjonen brytes ned i mindre, selvstendige tjenester som kommuniserer gjennom API-kall. Hver mikrotjeneste fungerer som en egen enhet med sin egen stack, inkludert separate databaser og databasehåndteringssystemer. Ofte er det slik at ett team eller en enkelt person har ansvar for en spesifikk mikrotjeneste, noe som gir klare ansvarsområder og muliggjør raskere utvikling og vedlikehold.
Kommunikasjonen i mikrotjenestearkitektur skjer vanligvis ved en kombinasjon av REST-APIer, event streaming og meldingsmeglere (message brokers). Selv om mikrotjenester ofte beskrives i en arkitektonisk kontekst, er det nyttig å forstå dem gjennom deres praktiske fordeler. For eksempel gir arkitekturen fleksibilitet til å endre og oppdatere kode uten å påvirke andre tjenester. Den muliggjør også bruken av skalerbare komponenter som opererer uavhengig av hverandre, noe som kan forbedre robusthet og ytelse i komplekse systemer.
1.	Automatisering og kontinuerlig levering (CI/CD)
Serverløs arkitektur: Implementering av en serverløs arkitektur i CI/CD-pipelines innebærer vanligvis utrulling av et stort antall små, selvstendige funksjoner som kan ha ulike avhengigheter, konfigurasjoner og versjoner. Dette kan gjøre automatiseringen mer kompleks, ettersom hver funksjon må deployeres raskt og potensielt i mindre grupper, avhengig av behovene til applikasjonen. Selv om verktøy som AWS SAM og Serverless Framework bidrar til å forenkle prosessen, kan det fortsatt oppstå utfordringer med å holde oversikt over alle avhengigheter, versjonering og sikringen av at funksjonene fungerer godt sammen. I tillegg må det tas hensyn til orkestrering og overvåking av flere, uavhengige funksjoner for å unngå uventede feil og nedetid.
En interessant implikasjon ved å bruke en serverløs arkitektur, er muligheten til å bryte ned en tradisjonell mikrotjeneste, til flere selvstendige lambda-funksjoner, som har hver sine ansvarsområder. Dette kan resultere i økt modularitet, men også til økte krav om håndtering og overvåkning. Ved å benytte seg av Amazon SQS (Simple Query Service) kan disse kobles sammen gjennom meldingsbasert kommunikasjon. Tjenesten fungerer som en meldingskø og sørger for løs kobling mellom funksjonene, og tillater asynkron behandling av oppgaver. Denne løsningen kan bidra til en økt fleksibilitet i systemet ettersom den kan la funksjoner kjøre uavhengig av hverandre, samtidig som den gir en buffer mellom komponentene og kan gjøre det lettere å håndtere den varierende belastningen. På denne måten sikrer SQS mer robusthet og skalerbarhet, men introduserer også et behov for mer orkestrering og overvåkning av meldingsflyten.
Mikrotjenestearkitektur: CI/CD-pipelines i en mikrotjenestearkitektur er ofte fokusert på et større antall tjenester, hvor hver tjeneste vanligvis har sitt eget miljø og pipeline, men ofte med færre komponenter å holde oversikt over sammenlignet med en serverløs arkitektur. Bruk av containere gir en enhetlig og konsekvent måte å håndtere hele miljøer på, noe som bidrar til bedre kontroll over avhengigheter og konfigurasjoner. Det gir også bedre muligheter for isolert testing og versjonskontroll av hver mikrotjeneste, samtidig som de kan integreres i større systemer ved hjelp av verktøy som Docker og Kubernetes. Denne strukturerte tilnærmingen forenkler implementering av større endringer i enkeltstående tjenester uten å påvirke andre tjenester. Utfordringer med pipelines knyttet til denne arkitekturen kan for eksempel være; mange uavhengige kodebaser, som kan føre til at kunnskap om hvordan man bygger systemet er spredt utover forskjellige team. Ulike programmeringsspråk og rammeverk kan skape utfordringer under utviklingen av en enkeltstående byggeprosess som skal håndtere alle språkene. Derfor er det viktig å ta for seg disse problemstillingene tidlig for å unngå teknisk gjeld. 
Sammenlikning: Implementeringen av CI/CD varierer betraktelig mellom en serverløs arkitektur og mikrotjenestearkitektur, hvor hver av tilnærmingene har egne fordeler og utfordringer. Serverløs arkitektur muliggjør en raskere utrulling og lavere operasjonell kompleksitet, men kan gjøre det vanskeligere å håndtere avhengigheter og miljøkontroll. Mikrotjenestearkitekturen vil gi en mer robust deploymentprosess og containerisolasjon, men vil kreve en mer kompleks infrastruktur. Begge tilnærmingene vil altså støtte DevOps-målet om raskere og mer pålitelig utvikling, men baserer seg på forskjellige strategier ettersom serverløs fokuserer på rask levering og mindre vedlikeholdstid, sett i kontekst av mikrotjenestearkitekturens fokus på mer tradisjonell kontroll og fleksibilitet. Den beste strategien vil variere avhengig av prosjektets behov, krav om skalering og utviklernes kompetanse. 
2.	Observability (overvåkning)
Før vi kan drøfte observability i detalj, er det viktig å klargjøre forskjellene mellom overvåkning og monitorering av systemer. Monitorering referer i hovedsak til en systematisk innhenting og visualisering av data fra systemet. overvåkning representerer en mer omfattende tilnærming som strekker seg utover den rene datainnsamlingen. Der monitorering tillater oss å få et øyeblikksbilde av programmets ytre tilstand, vil overvåkning gjøre det mulig å få en dypere forståelse av applikasjonens interne tilstand og oppførsel. Selv om monitorering fungerer som en komponent i overvåkningsprosessen, er det først etter den innsamlede dataen analyseres og tolkes i kontekst at vi oppnår faktisk overvåkning. Dette skillet er relevant når vi skal vurdere forskjellene mellom mikrotjenestearkitektur og serverløs arkitektur. 
Mikrotjenester: Overvåkning av disse to arkitekturene tydeliggjør en markant forskjell i hvordan prinsippet håndteres. I en mikrotjenestearkitektur har man tradisjonelt mer kontroll over logging, sporing og overvåkning av hendelser på grunn av direkte tilgang til infrastrukturen. Ved å benytte verktøy som Prometheus, Grafana og ELK-stacken (Elasticsearch, Logstash og Kibana) får utviklere detaljert innsikt i avhengigheter og tjenestenes oppførsel. Denne typen verktøy gjør det enklere å avdekke feil på tvers av de ulike tjenestene med høy presisjon. Overvåkningen støtter komplekse distribuerte systemer hvor koordinering er avgjørende. 
Serverløs arkitektur: I en serverløs arkitektur er overvåkning derimot mer utfordrende. Selv om ulike CSP-er (Cloud Service Providers) tilbyr verktøy som CloudWatch og Lambda Insights, innebærer serverløs arkitektur mindre direkte kontroll over infrastrukturen. Serverløse funksjoner opererer i kortvarige miljøer, noe som gjør overvåkning og feilsøking mer komplekst. Utfordringer som «cold starts» kan skape forsinkelser, og det kan være vanskelig å spore transaksjonsforløp på tvers av mange små, uavhengige funksjoner. Dette fører til behov for mer dynamisk overvåkning, ofte ved hjelp av verktøy som AWS X-Ray.
En annen utfordring er kontekstsammenheng mellom serverløse funksjoner. I mikrotjenester er det ofte enklere å bruke «Correlation IDs» for å spore transaksjoner på tvers av tjenester. Dette kan være mer utfordrende i en serverløs arkitektur, hvor løsninger som OpenTelemetry eller tredjepartsverktøy som Honeycomb og DataDog kan gi bedre innsikt og kartlegging av systemets ytelse. Siden serverløse funksjoner kan skaleres til null og aktiveres igjen ved plutselige trafikkendringer, krever det en mer fleksibel og dynamisk overvåkningstilnærming.
Denne kontrasten i overvåkningsmetodikk viser hvordan mikrotjenester gir utviklere mer direkte kontroll og detaljert innsikt, mens serverløs arkitektur krever nye overvåkningsstrategier for å håndtere komplekse og raskt skiftende funksjonelle behov.
3.	Skalerbarhet og kostnadskontroll
Skalerbarhet og kostnadskontroll representerer kritiske aspekter i moderne systemarkitektur, når vi sammenlikner serverløs- og mikrotjenestearkitektur, ser vi fundamentale forskjeller i hvordan disse tilnærmingene håndterer automatikk i skalering og kostnadsoptimalisering. Disse forskjellene påvirker både utviklingsteamets arbeidsprosesser og systemets totale eierkostnad (TCO) direkte.
Serverløs: I en serverløs tilnærming finnes det ofte innebygde muligheter for skalerbarhet, som ofte skjer automatisk og er drevet av tjenestetilbyderen. Tjenester som AWS lambda har muligheten til å håndtere fra 1 til 1000 samtidige eksekveringer per region (med mulighet for økning), ved å lese trafikkmønsteret og skalere enten opp eller ned basert på denne informasjonen. Dette utspiller seg uten at utviklere trenger å håndtere denne skaleringen manuelt. Dette er en stor fordel i systemer hvor trafikkmønsteret eller belastningsmønsteret er uforutsigbart da kapasiteten kan tilpasses på millisekundsnivå. Denne kostnaden bunner derfor sterkt i faktisk ressursbruk – altså vil du kun faktureres for tiden funksjonene faktisk kjører, og kan resultere i markante besparelser i applikasjoner med varierende last og funksjoner som sjeldent påkalles. 
Imidlertid har også denne tilnærmingen noen ulemper: Applikasjoner som inneholder tunge, langvarige prosesser eller som kjøres kontinuerlig kan medføre at de hyppige kallene til små serverløse funksjoner blir dyrere enn de mer tradisjonelle metodene. En annen utfordring er problemer som omhandler «Cold-start» hvor forsinkelser i initialisering for å starte en ny instans kan påvirke applikasjonens ytelse ved plutselig økning av trafikk. I tillegg er det stor sannsynlighet for at behovet for å optimalisere kostnader og kompleksiteten vokse i takt med antall funksjoner og tjenester – dette krever mer overvåkning og styring. 
Som nevnt under delen om automatisering og kontinuerlig levering, muliggjør SQS en dynamisk skalering ved å fungere som en meldingsbuffer. I et serverløst oppsett kan en mikrotjeneste splittes opp til flere selvstendige lambda-funksjoner, når belastningen øker, vil det automatisk startes flere instanser av funksjonene for å håndtere meldinger i køen. Dette tillater tilpasset ressursbruk basert på de faktiske behovene. Imidlertid kan det oppsettet føre til høyere kompleksitet i form av versjonskontroll, orkestrering og overvåkning av flere små funksjoner. Derfor bør kostnads- og skaleringsimplikasjoner nøye vurderes før en beslutnin
Mikrotjenester: I en tilnærming som benytter seg av mikrotjenestearkitektur, håndteres skalerbarheten tradisjonelt sett ved bruk av containere og container-orkestreringssystemer som Kubernetes. De individuelle tjenestene kan skaleres manuelt, men dette krever en mer manuell tilnærming med oppsett og vedlikehold. For systemer med mer forutsigbar og kontinuerlig belastning kan dette være en fordel da det åpner for muligheten til optimalisering på detaljnivå og økt ytelse 
Kostnadsmessig kan denne tilnærmingen være mer gunstig for visse brukstilfeller, hvor belastningen utgjør et behov for at en rekke tjenester kjøres kontinuerlig, ettersom dette utgjør mer forutsigbare kostnader. Ulempen er derfor at skaleringsstrategier krever mer manuelt arbeid og ressurser fra DevOps-teamet, spesielt i tilfeller som omhandler oppsett, vedlikehold, balansering av last, konfigurere replisering og håndteringen av et høyt antall containere. 
Altså vil en serverløs tilnærming tilby bedre fleksibilitet og ressursoptimalisering i scenarioer med varierende trafikk, og en mikrotjenestearkitektur vil gi større kontroll over skalerbarhet og mer forutsigbare kostander. Valget mellom de to vil derfor variere ut ifra brukstilfellet, belastningsmønsteret og hvilke ressurser en har mulighet til eller ønsker å allokere til drift og vedlikehold. 
4.	Eierskap og ansvar:
En overgang mellom mikrotjeneste- og serverløs arkitektur medfører endringer i hvordan DevOps-team bør forvalte eierskap og ansvar. Denne overgangen påvirker arbeidsflyt, ressursfordeling og teamstruktur.
Serverløs arkitektur: Ansvaret for infrastrukturen overføres i stor grad til en ekstern CSP, som vil frigjøre utviklerne fra å håndtere oppgaver som oppdateringer, sikkerhet og drift av servere. Dette tillater teamene muligheten til å fokusere mer på selve utviklingen av applikasjonslogikken, og kan gjøre det lettere å møte forretningskrav. Samtidig kan dette føre til redusert kontroll over infrastrukturen, noe som igjen vil øke kravet til forståelse av CSP-verktøy og begrensninger.
Overgangen til mindre selvstendige lambda-funksjoner innebærer flere selvstendige enheter med hver sine livssykluser, noe som kan skape kompleksitet i funksjonsstyring. Dette skaper: et økt behov for versjonskontrollsystemer som håndterer funksjoner individuelt, et krav til tydelig dokumentasjon av de ulike avhengighetene som tilhører funksjonen for å sikre kontinuitet, og et behov for koordinering mellom de forskjellige teamene som arbeider med tett koblede funksjoner gjennom meldingskøer eller API-er.
Kostnadsansvar i serverløs arkitektur er direkte knyttet til bruk. Dette betyr at teamene blir nødt til å gjennomføre jevn overvåkning av forbruksmønsteret for å identifisere unødige kall til funksjoner og optimalisere kjøretid og minnebruk, men også implementere kostnadsstyringsverktøy som AWS Cost Explorer for å sikre en økonomisk effektivitet. Denne fleksibiliteten kan som oftest være en fordel, men krever dedikert oppmerksomhet for å unngå overskridelser av budsjetter.
Mikrotjenestearkitektur: Mikrotjenestearkitektur kjennetegnes ved at de forskjellige teamene har et helhetlig eierskap over sine tjenester, inkludert infrastrukturadministrasjon, implementering av egne utrullingsstrategier som ofte skjer ved bruk av containere og Kubernetes. Ytelsesoptimalisering og oppsett av skaleringsmekanismer. Denne tilnærmingen gir utviklerne betydelig kontroll, og åpner for muligheten til detaljert skaleringsdesign og ytelsesoptimalisering, men medfører også et mer komplekst ansvarsbilde da de nå selv er ansvarlige for kontinuerlig vedlikehold, feilsøking, og sikring av tjenestenes pålitelighet. Altså vil dette kreve mer ressurser og teknisk kompetanse, men tilbyr muligheten for en dypere forståelse og direkte kontroll over den underliggende infrastrukturen og de funksjonelle komponentene som tilhører systemet.
De klare grensene som tydeliggjøres gir en avgrensing mellom de ulike tjenestene. Dette gir teamene muligheten til å definere spesifikke ansvarsområder i de ulike tjenestene med høy presisjon, samtidig som det forenkler sporing av ytelse og identifikasjon av potensielle flaskehalser på tjenestenivå. Ved å jobbe innenfor disse tjenestegrensene, kan team lettere isolere og diagnostisere problemer, som igjen vil effektivisere prosesser som feilsøking, og muliggjør mer målrettede ytelsesforbedringer.
Den økte kontrollen i mikrotjenestearkitekturen medfører også høyere krav til kompetanse innen administrasjonen av infrastrukturen og DevOps-praksis. Dette innebærer ikke bare vedlikehold av servere og containermiljøer, men også optimalisering av ressursbruk og kostnader gjennom egne predefinerte strategier. Dette krever dypere forståelse av arkitekturen, containerorkestreringen og skyinfrastrukturen for å effektivt vedlikeholde og implementere mikrotjenestesystemer.
Overgangen mellom serverløs arkitektur og mikrotjenestearkitektur tydeliggjør skiftet i DevOps-teamenes eierskap og ansvarsområder. Serverløse tilnærminger overfører ansvaret for infrastruktur til en skytjenesteleverandør, som kan frigjøre utviklere til å fokusere på forretningslogikken, men krever en grundigere forståelse av skyplattformens verktøy og begrensninger. Kompleksiteten ved mange små selvstendige funksjoner må håndteres av teamene ved grundig versjonskontroll og koordinering, på denne måten blir kostnadene mer dynamisk, og knyttes direkte til den faktiske ressursbruken og behovet for kontinuerlig optimalisering. Til sammenligning vil mikrotjenestearkitektur gi utviklerne full kontroll over infrastruktur, strategier for deployment og ytelsesoptimalisering, men setter krav om mer teknisk kompetanse, mer ressurser og totalt et mer avansert vedlikeholdsansvar. Derfor avhenger valget mellom disse to arkitekturene av organisasjonens tekniske kapasitet og spesifikke forretningsbehov.
